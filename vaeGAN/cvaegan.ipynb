{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Conditional VAE-GAN\n",
        "\n",
        "[![Package badge]][github]\n",
        "[![Open In Colab]][notebook]\n",
        "\n",
        "[github]:https://github.com/tarepan/VAE-GAN\n",
        "[notebook]:https://colab.research.google.com/github/tarepan/VAE-GAN/blob/main/vaeGAN/cvaegan.ipynb\n",
        "[Package badge]:https://img.shields.io/badge/GitHub-vaeagn-9cf.svg\n",
        "[Open In Colab]:https://colab.research.google.com/assets/colab-badge.svg"
      ],
      "metadata": {
        "id": "jdmEOXaZ1PNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "2GOIiUn-1Sdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tarepan/VAE-GAN.git\n",
        "%cd \"./VAE-GAN/vaeGAN\""
      ],
      "metadata": {
        "id": "sQgp_Usu0k5G",
        "outputId": "301d905a-5dfe-4bb8-e3ef-98cebb7c9ab9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VAE-GAN'...\n",
            "remote: Enumerating objects: 34420, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 34420 (delta 0), reused 3 (delta 0), pack-reused 34413\u001b[K\n",
            "Receiving objects: 100% (34420/34420), 118.19 MiB | 17.87 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "tbV0HBc62Woa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ../results/cvaegan_results"
      ],
      "metadata": {
        "id": "xAvx-wKUfOvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image"
      ],
      "metadata": {
        "id": "6Vkg4CtP2X5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "GpzZhjJ-2aIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from vaegan import VAE\n",
        "from vaegan import NetD\n",
        "from vaegan import Aux\n",
        "from vaegan import loss_function\n",
        "\n",
        "\n",
        "bsz = 128\n",
        "\n",
        "dataset_train = datasets.MNIST('../data', download=True,                transform=transforms.ToTensor())\n",
        "dataset_test  = datasets.MNIST('../data',                train = False, transform=transforms.ToTensor())\n",
        "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=bsz, shuffle=True, drop_last=True)\n",
        "test_loader  = torch.utils.data.DataLoader(dataset_test,  batch_size=bsz, shuffle=True, drop_last=True)\n",
        "\n",
        "encoder = VAE()\n",
        "decoder = Aux()\n",
        "disc    = NetD()\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "optim_disc = optim.Adam(disc.parameters(), lr=1e-4)\n",
        "optim_enc  = optim.Adam(encoder.parameters(), lr=1e-4)\n",
        "optim_dec  = optim.Adam(decoder.parameters(),  lr=1e-4)\n",
        "\n",
        "encoder, decoder = encoder.cuda(), decoder.cuda()\n",
        "disc = disc.cuda()\n",
        "criterion =criterion.cuda()\n",
        "\n",
        "ones  = torch.ones(bsz).cuda()\n",
        "zeros = torch.zeros(bsz).cuda()\n",
        "\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "for epoch in range(200):\n",
        "    print(f'start epoch #{epoch}')\n",
        "\n",
        "    for i, (data, y) in enumerate(train_loader):\n",
        "        #### Step ################################################\n",
        "        # Data - Digit image 28x28 & Digit label\n",
        "        real, y = data.cuda(), y.cuda()\n",
        "\n",
        "        # Common_Forward\n",
        "        ## Encode\n",
        "        mu, logvar = encoder(real, y)\n",
        "        ## Sampling - Posterior and Prior\n",
        "        ### Prior\n",
        "        z_p = torch.empty_like(mu).normal_()\n",
        "        ### Posterior\n",
        "        eps = torch.empty_like(mu).normal_()\n",
        "        z_q = mu + eps * torch.exp(logvar * 0.5)\n",
        "        ## Decode\n",
        "        fake     = decoder(z_q, y)\n",
        "        fake_aux = decoder(z_p, y)\n",
        "\n",
        "        # D_Forward\n",
        "        d_feat_fake, d_fake     = disc(fake,     y)\n",
        "        d_feat_real, d_real     = disc(real,     y)\n",
        "        _,           d_fake_aux = disc(fake_aux, y)\n",
        "        # D_Loss/Backward/Optim\n",
        "        loss_adv_d_real = criterion(d_real.squeeze(1), ones)\n",
        "        loss_adv_d_fake = criterion(d_fake.squeeze(1), zeros)\n",
        "        loss_adv_d = loss_adv_d_real + loss_adv_d_fake\n",
        "        loss_adv_d_fake_aux = criterion(d_fake_aux.squeeze(1), zeros)\n",
        "        loss_aux = loss_adv_d_fake_aux\n",
        "        loss_disc = loss_adv_d + loss_aux\n",
        "        disc.zero_grad()\n",
        "        loss_disc.backward(retain_graph=True)\n",
        "        optim_disc.step()\n",
        "\n",
        "        # # G_Loss, without adversarial encoder learning\n",
        "        # loss_vae = loss_function(d_feat_fake, d_feat_real, mu, logvar)\n",
        "\n",
        "        # # Dec_Loss/Backward/Optim\n",
        "        # loss_adv_g     = criterion(d_fake.squeeze(1),     ones)\n",
        "        # loss_adv_g_aux = criterion(d_fake_aux.squeeze(1), ones)\n",
        "        # loss_dec = loss_adv_g + loss_adv_g_aux + loss_vae\n",
        "        # decoder.zero_grad()\n",
        "        # loss_dec.backward(retain_graph=True)\n",
        "        # optim_dec.step()\n",
        "\n",
        "        # # Enc_Loss/Backward/Optim\n",
        "        # loss_enc = loss_vae\n",
        "        # encoder.zero_grad()\n",
        "        # loss_enc.backward()\n",
        "        # optim_enc.step()\n",
        "\n",
        "        # G_Loss/Backward/Optim, with adversarial encoder learning\n",
        "        loss_adv_g_zq = criterion(d_fake_zq.squeeze(1), ones)\n",
        "        loss_adv_g_zp = criterion(d_fake_zp.squeeze(1), ones)\n",
        "        loss_vae = loss_function(d_feat_fake, d_feat_real, mu, logvar)\n",
        "        loss_g = loss_adv_g_zq + loss_adv_g_zp + loss_vae\n",
        "        encoder.zero_grad()\n",
        "        decoder.zero_grad()\n",
        "        loss_g.backward()\n",
        "        optim_dec.step()\n",
        "        optim_enc.step()\n",
        "\n",
        "        # Logging\n",
        "        if i % 2000 == 0:\n",
        "            save_image(real,                       '../results/cvaegan_results/train2_real_samples2.png', normalize=True)\n",
        "            save_image(fake.data.view(-1,1,28,28), '../results/cvaegan_results/train2_fake_samples2.png', normalize=True)\n",
        "        #### /Step ###############################################\n",
        "\n",
        "    if epoch % 25 == 0:\n",
        "        save_image(fake.data.view(-1,1,28,28), '../results/cvaegan_results/train2_fake_samples2_{0}.png'.format(epoch), normalize=True)\n",
        "\n",
        "# torch.save(encoder, './pretrained models/encoder3.pth')\n",
        "# torch.save(disc,    './pretrained models/disc3.pth')\n",
        "# torch.save(decoder, './pretrained models/decoder3.pth')\n"
      ],
      "metadata": {
        "id": "WIXj-DL22bZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "fBeDcMAM2pe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "netG = torch.load('pretrained_models/netG2.pth')\n",
        "netD = torch.load('pretrained_models/netD2.pth')\n",
        "aux  = torch.load('pretrained_models/aux2.pth')\n",
        "\n",
        "test_dataset = datasets.MNIST('../data', train=False, transform=transforms.ToTensor())\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=bsz, shuffle=True)\n",
        "\n",
        "data, y = iter(test_loader).next()\n",
        "save_image(data.view(-1,1,28,28), './fake.png', normalize=True)"
      ],
      "metadata": {
        "id": "UldZRfTN2qnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "mu,logvar = netG(Variable(data).cuda(), Variable(y).cuda(), Variable(torch.tensor([8])).cuda(), .5)\n",
        "std = logvar.mul(0.5).exp_()\n",
        "eps = Variable(std.data.new(std.size()).normal_())\n",
        "z=eps.mul(std).add_(mu)\n",
        "fake = aux(z, y, Variable(torch.tensor([8])).cuda(), .5)\n",
        "save_image(fake.data.view(-1,1,28,28), './results/cvae results/generated2.png', normalize=True)\n",
        "\n",
        "mu,logvar = netG(Variable(fake), Variable(y).cuda())\n",
        "std = logvar.mul(0.5).exp_()\n",
        "eps = Variable(std.data.new(std.size()).normal_())\n",
        "z=eps.mul(std).add_(mu)\n",
        "fake2 = aux(z, y)\n",
        "save_image(fake2.data.view(-1,1,28,28), './results/cvae results/generated3.png', normalize=True)\n",
        "\n",
        "mu,logvar = netG(Variable(data).cuda(), Variable(y).cuda(), Variable(torch.tensor([8])).cuda(), 1)\n",
        "std = logvar.mul(0.5).exp_()\n",
        "eps = Variable(std.data.new(std.size()).normal_())\n",
        "z=eps.mul(std).add_(mu)\n",
        "fake = aux(z, y, Variable(torch.tensor([8])).cuda(), 1)\n",
        "save_image(fake.data.view(-1,1,28,28), './results/cvae results/generated.png', normalize=True)"
      ],
      "metadata": {
        "id": "IjHL8wH021ZO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}