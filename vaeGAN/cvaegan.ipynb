{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Conditional VAE-GAN\n",
        "\n",
        "[![Package badge]][github]\n",
        "[![Open In Colab]][notebook]\n",
        "\n",
        "[github]:https://github.com/tarepan/VAE-GAN\n",
        "[notebook]:https://colab.research.google.com/github/tarepan/VAE-GAN/blob/main/vaeGAN/cvaegan.ipynb\n",
        "[Package badge]:https://img.shields.io/badge/GitHub-vaeagn-9cf.svg\n",
        "[Open In Colab]:https://colab.research.google.com/assets/colab-badge.svg"
      ],
      "metadata": {
        "id": "jdmEOXaZ1PNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "2GOIiUn-1Sdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tarepan/VAE-GAN.git\n",
        "%cd \"./VAE-GAN/vaeGAN\""
      ],
      "metadata": {
        "id": "sQgp_Usu0k5G",
        "outputId": "301d905a-5dfe-4bb8-e3ef-98cebb7c9ab9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VAE-GAN'...\n",
            "remote: Enumerating objects: 34420, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 34420 (delta 0), reused 3 (delta 0), pack-reused 34413\u001b[K\n",
            "Receiving objects: 100% (34420/34420), 118.19 MiB | 17.87 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "tbV0HBc62Woa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image"
      ],
      "metadata": {
        "id": "6Vkg4CtP2X5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "GpzZhjJ-2aIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from vaegan import VAE\n",
        "from vaegan import NetD\n",
        "from vaegan import Aux\n",
        "from vaegan import loss_function\n",
        "\n",
        "\n",
        "bsz = 128\n",
        "\n",
        "dataset_train = datasets.MNIST('../data', download=True,                transform=transforms.ToTensor())\n",
        "dataset_test  = datasets.MNIST('../data',                train = False, transform=transforms.ToTensor())\n",
        "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=bsz, shuffle=True)\n",
        "test_loader  = torch.utils.data.DataLoader(dataset_test,  batch_size=bsz, shuffle=True)\n",
        "\n",
        "netG = VAE()\n",
        "netD = NetD()\n",
        "aux = Aux()\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "optimizerD    = optim.Adam(netD.parameters(), lr=1e-4)\n",
        "optimizerG    = optim.Adam(netG.parameters(), lr=1e-4)\n",
        "optimizer_aux = optim.Adam(aux.parameters(),  lr=1e-4)\n",
        "\n",
        "input = torch.FloatTensor(bsz,28,28)\n",
        "label = torch.FloatTensor(bsz)\n",
        "real_label=1\n",
        "fake_label=0\n",
        "\n",
        "netG=netG.cuda()\n",
        "netD=netD.cuda()\n",
        "aux = aux.cuda()\n",
        "criterion=criterion.cuda()\n",
        "input, label = input.cuda(), label.cuda()\n",
        "\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "for epoch in range(200):\n",
        "    for i, (data, y) in enumerate(train_loader):\n",
        "        #### Step ################################################\n",
        "        gamma = 1.0\n",
        "        real_cpu = data;\n",
        "\n",
        "        # Data\n",
        "        real_cpu = real_cpu.cuda()\n",
        "        y=y.cuda()\n",
        "        input.resize_as_(real_cpu).copy_(real_cpu)\n",
        "        label.resize_(bsz).fill_(real_label)\n",
        "        inputv = Variable(input) # Digit image 28x28\n",
        "        y      = Variable(y)     # Digit label\n",
        "        labelv = Variable(label) # Real label\n",
        "\n",
        "        netD.zero_grad()\n",
        "\n",
        "        # Common_Forward\n",
        "        ## Encode\n",
        "        mu, logvar = netG(inputv, y)\n",
        "        ## Sampling\n",
        "        std = logvar.mul(0.5).exp_()\n",
        "        eps = Variable(std.data.new(std.size()).normal_())\n",
        "        z=eps.mul(std).add_(mu)\n",
        "        ## Decode\n",
        "        fake = aux(z, y)\n",
        "\n",
        "        # D_Forward\n",
        "        x_l_tilde, output_fake = netD(fake,   y)\n",
        "        x_l,       output_real = netD(inputv, y)\n",
        "        # D_Loss/Backward\n",
        "        L_GAN_real = criterion(output_real.squeeze(1), labelv)\n",
        "        L_GAN_real.backward(retain_graph=True)\n",
        "        labelv = Variable(label.fill_(fake_label))\n",
        "        L_GAN_fake = criterion(output_fake.squeeze(1), labelv)\n",
        "        L_GAN_fake.backward(retain_graph=True)\n",
        "        # Unconditional generation?\n",
        "        z_p = Variable(std.data.new(std.size()).normal_())\n",
        "        fake_aux = aux(z_p, y)\n",
        "        x_l_aux, output_aux = netD(fake_aux, y)\n",
        "        L_GAN_aux = criterion(output_aux.squeeze(1), labelv)\n",
        "        L_GAN_aux.backward(retain_graph=True)\n",
        "        # D_Optim\n",
        "        optimizerD.step()\n",
        "\n",
        "        aux.zero_grad()\n",
        "        labelv=Variable(label.fill_(real_label))\n",
        "\n",
        "        L_dec_vae = gamma * loss_function(x_l_tilde, x_l, mu, logvar)\n",
        "        L_dec_fake = criterion(output_fake.squeeze(1), labelv)\n",
        "        L_dec_aux  = criterion(output_aux.squeeze(1),  labelv)\n",
        "        L_dec_vae.backward(retain_graph=True)\n",
        "        L_dec_fake.backward(retain_graph=True)\n",
        "        L_dec_aux.backward(retain_graph=True)\n",
        "        optimizer_aux.step()\n",
        "\n",
        "        #encoder loss\n",
        "        netG.zero_grad()\n",
        "        L_enc = loss_function(x_l_tilde, x_l, mu, logvar)\n",
        "        L_enc.backward()\n",
        "        optimizerG.step()\n",
        "\n",
        "        # Logging\n",
        "        if i % 100 == 0:\n",
        "            print('real_cpu.size()', real_cpu.size(), \"iteration: \", i)\n",
        "            save_image(real_cpu,                   './results/cvaegan results/real_samples2.png', normalize=True)\n",
        "            save_image(fake.data.view(-1,1,28,28), './results/cvaegan results/fake_samples2.png', normalize=True)\n",
        "        #### /Step ###############################################\n",
        "\n",
        "    if epoch % 25 == 0:\n",
        "        print('epoch: ', epoch)\n",
        "        save_image(fake.data.view(-1,1,28,28), '../results/cvaegan results/fake_samples2_{0}.png'.format(epoch), normalize=True)\n",
        "\n",
        "# torch.save(netG, './pretrained models/netG3.pth')\n",
        "# torch.save(netD, './pretrained models/netG3.pth')\n",
        "# torch.save(aux, './pretrained models/netG3.pth')\n"
      ],
      "metadata": {
        "id": "WIXj-DL22bZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "fBeDcMAM2pe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "netG = torch.load('pretrained_models/netG2.pth')\n",
        "netD = torch.load('pretrained_models/netD2.pth')\n",
        "aux  = torch.load('pretrained_models/aux2.pth')\n",
        "\n",
        "test_dataset = datasets.MNIST('../data', train=False, transform=transforms.ToTensor())\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=bsz, shuffle=True)\n",
        "\n",
        "data, y = iter(test_loader).next()\n",
        "save_image(data.view(-1,1,28,28), './fake.png', normalize=True)"
      ],
      "metadata": {
        "id": "UldZRfTN2qnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "mu,logvar = netG(Variable(data).cuda(), Variable(y).cuda(), Variable(torch.tensor([8])).cuda(), .5)\n",
        "std = logvar.mul(0.5).exp_()\n",
        "eps = Variable(std.data.new(std.size()).normal_())\n",
        "z=eps.mul(std).add_(mu)\n",
        "fake = aux(z, y, Variable(torch.tensor([8])).cuda(), .5)\n",
        "save_image(fake.data.view(-1,1,28,28), './results/cvae results/generated2.png', normalize=True)\n",
        "\n",
        "mu,logvar = netG(Variable(fake), Variable(y).cuda())\n",
        "std = logvar.mul(0.5).exp_()\n",
        "eps = Variable(std.data.new(std.size()).normal_())\n",
        "z=eps.mul(std).add_(mu)\n",
        "fake2 = aux(z, y)\n",
        "save_image(fake2.data.view(-1,1,28,28), './results/cvae results/generated3.png', normalize=True)\n",
        "\n",
        "mu,logvar = netG(Variable(data).cuda(), Variable(y).cuda(), Variable(torch.tensor([8])).cuda(), 1)\n",
        "std = logvar.mul(0.5).exp_()\n",
        "eps = Variable(std.data.new(std.size()).normal_())\n",
        "z=eps.mul(std).add_(mu)\n",
        "fake = aux(z, y, Variable(torch.tensor([8])).cuda(), 1)\n",
        "save_image(fake.data.view(-1,1,28,28), './results/cvae results/generated.png', normalize=True)"
      ],
      "metadata": {
        "id": "IjHL8wH021ZO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}